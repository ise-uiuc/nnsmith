## Bugs found with NNSmith

> **Annotation**: 锔 means fixed;  means this bug has been marked with a `high-priority` label (PyTorch)

### Table of Contents

* [**PyTorch**](#pytorch)
* [**PyTorch-ONNX Converter**](#pytorch-onnx-converter)
* [**ONNX**](#onnx)
* [**ONNXRuntime**](#onnxruntime)
* [**TVM**](#tvm)
* [**TensorRT**](#tensorrt)
* [**TensorFlow**](#tensorflow)
* [**Methodology**](#methodology)

### PyTorch

01. 锔  [SIGIOT when running model with conv2d and avgpool2d after `optimize_for_inference` 路 Issue #86535 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/86535)

02. 锔 [`optimize_for_inference` leads to wrong results for model with conv2d, max and clip 路 Issue #86556 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/86556)

03. 锔  [RuntimeError: could not construct a memory descriptor using a format tag 路 Issue #86664 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/86664)

04. 锔 [[NNPack] Runtime error with padded `Conv1d` and `>=16` batch size 路 Issue #90142 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/90142)

05. 锔  [[pt2] `torch.where` gives wrong results with `torch.compile` 路 Issue #93374 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93374)

06.  [[pt2] compiled function with cat and mul gives wrong results 路 Issue #93365 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93365)

07. 锔 [[pt2] cannot compile model with linear layer when the input has rank 1 路 Issue #93372 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93372)

08. 锔 [[pt2] `torch._inductor.exc.CppCompileError: C++ compile error` when compiling `neg` and `max` 路 Issue #93380 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93380)

09. 锔 [[pt2] `torch.compile` produces wrong results for function with `neg` on `uint8` tensor 路 Issue #93829 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93829)

10. 锔 [[pt2] Cannot compile model with `neg` and `linear` 路 Issue #93836 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93836)

11. 锔 [`pad` + `gt` produce wrong results in compile mode 路 Issue #93351 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93351)

12. 锔 [[pt2] `torch._inductor.exc.CppCompileError: C++ compile error` when compiling `argmax` and `min` 路 Issue #94055 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/94055)

13. 锔 [`torch.compile` fails when using `torch.sub` with python constant 路 Issue #95181 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/95181)

14. 锔 [`torch.ge` produces wrong results in compile mode when given int tensors 路 Issue #95695 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/95695)

15. [[JIT] Zero-channel conv2d cannot be applied with `optimize_for_inference` 路 Issue #91396 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/91396)

16. [`min` reduction on float16 tensor failed on certain shapes 路 Issue #93249 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93249)

17. [`torch.compile` produce wrong result in `interpolate` when `mode=bilinear` 路 Issue #93262 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93262)

18. [[pt2] compiled model with cat and expand gives wrong results 路 Issue #93357 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/93357)

19. [Adding a linear layer leads to failure of `optimize_for_mobile` 路 Issue #86667 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/86667)

### PyTorch-ONNX Converter

01. 锔 [[ONNX] `f64 * LeakyReLU(f64)` mistakingly returns f32 路 Issue #85316 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/85316)

02. 锔 [[ONNX] Converter did not consider the implicit casting specifically for `Max` 路 Issue #87609 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/87609)

03. 锔 [fix: onnx PReLU unidirectional broadcasting by ganler 路 Pull Request #70571 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/70571)

04. 锔 [Clip] [[ONNX] Make Non-Float Op Exportation Compatible to Avoid Invalid ONNX Models by ganler 路 Pull Request #72401 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/72401)

05. 锔 [Min] [[ONNX] Make Non-Float Op Exportation Compatible to Avoid Invalid ONNX Models by ganler 路 Pull Request #72401 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/72401)

06. 锔 [Max] [[ONNX] Make Non-Float Op Exportation Compatible to Avoid Invalid ONNX Models by ganler 路 Pull Request #72401 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/72401)

07. 锔 [ReLU] [[ONNX] Make Non-Float Op Exportation Compatible to Avoid Invalid ONNX Models by ganler 路 Pull Request #72401 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/72401)

08. 锔 [Pad] [[ONNX] Make Non-Float Op Exportation Compatible to Avoid Invalid ONNX Models by ganler 路 Pull Request #72401 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/72401)

09. 锔 [[onnx export] Add broadcast to matmul shape inference by lazycal 路 Pull Request #70534 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/70534)

10. 锔 [[Bug][ONNX] Specification Inconsistency in Flatten 路 Issue #74142 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/74142)

11. 锔 [[ONNX] Fix shape inconsistency when exporting scalar log2 by lazycal 路 Pull Request #78701 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/pull/78701)

12. 锔 [[ONNX Export] Interpolation likely should be exported with `half_pixel` instead of `pytorch_half_pixel` 路 Issue #79361 路 pytorch/pytorch 路 GitHub](https://github.com/pytorch/pytorch/issues/79361)

### ONNX

01. 锔 [[Bug] Checker misses data type mismatch for Max 路 Issue #4619 路 onnx/onnx 路 GitHub](https://github.com/onnx/onnx/issues/4619)

### ONNXRuntime

01. 锔 [Crashes when relu is followed by a clip 路 Issue #9753 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/9753)

02. 锔 [MatMul fusion failed at scalar input 路 Issue #10950 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/10950)

03. 锔 [GemmTransposeFusion error when C is transposed (`Gemm(A,B,Transpose(C)`), complained with confusing name `_transformed_transformed_transformed...` 路 Issue #12071 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/12071)

04. [[Bug] Mixing negative and positive paddings causes segfault/uninitialized memory values produced in reflected pad 路 Issue #11828 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/11828)

05. [Runtime Exception when relu is followed by a clip 路 Issue #10936 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/10936)

06. [Inconsistent result to NumPy and PyTorch when consecutively casting a float tensor to int32 and then to bool 路 Issue #11994 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/11994)

07. [Wrong output shape due to MergeShape failure 路 Issue #11870 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/11870)

08. [Wrong Floor output on very large input 路 Issue #12076 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/12076)

09. [Resize with mode linear always produces 0.5 on GPU regardless of the input 路 Issue #12091 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/12091)

10. [Resize with `nearest` mode have inconsistent results compared to PyTorch and TVM 路 Issue #12098 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/12098)

11. [Parameters are optimized out even if it is a needed return value 路 Issue #13425 路 microsoft/onnxruntime 路 GitHub](https://github.com/microsoft/onnxruntime/issues/13425)

### TVM

01. 锔 [[Bug] shape int32-int64 check error in `trilu`'s `te.compute` 路 Issue #13029 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/13029)

02. 锔 [[Bug] `trilu` not tagged with `injective` and thus miss reduce schedule 路 Issue #13030 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/13030)

03. 锔 [[Bug] Wrong results of `cast<int32>( cast<bool>(-1i64) )` 路 Issue #13048 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/13048)

04. 锔 [[BugFix] resolve integer 32. ~ 64. mismatch by casting by ganler 路 Pull Request #9582 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/9582)

05. 锔 [[onnx] fix onnx where broadcast by lazycal 路 Pull Request #10106 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10106)

06. 锔 [Fix broadcast InferCorrectLayout by lazycal 路 Pull Request #10156 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10156)

07. 锔 [[BUGFIX][ARITH] Fix FloorMod Simplifier by lazycal 路 Pull Request #10336 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10336)

08. 锔 [[BugFix]: select node type error in NarrowDataType pass by ganler 路 Pull Request #10519 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10519)

09. [[Bug] GetStoreRule failure at simple Conv2d + Squeeze model 路 Issue #10528 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/10528)

10. 锔 [[Relay][ONNX][Fix] Flatten in OnnxConverter by ganler 路 Pull Request #10593 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10593)

11. 锔 [NarrowDataType] [[TIR] Fix Ramp int32~64 mismatch in VectorizeLoop and NarrowDataType passes by lazycal 路 Pull Request #10172 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10172)

12. 锔 [VectorizeLoop] [[TIR] Fix Ramp int32~64 mismatch in VectorizeLoop and NarrowDataType passes by lazycal 路 Pull Request #10172 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10172)

13. 锔 [[Bug][TE Schedule] Unsupported nested parallel created by Softmax TE schedule 路 Issue #12001 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/12001)

14. 锔 [[fix] vec * mat in matmul in onnx converter by ganler 路 Pull Request #11174 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/11174)

15. 锔 [fix vec*mat in PyTorch converter by ganler 路 Pull Request #11347 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/11347)

16. 锔 [[TIR] Fix int32 vs int64 mismatch in For construct. by lazycal 路 Pull Request #10595 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10595)

17. 锔 [Add missing Slice layout fallback check of `stride=1` . by lazycal 路 Pull Request #10690 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10690)

18. 锔 [Onnx squeeze enabled with auto axis handling. by ganler 路 Pull Request #10742 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10742)

19. 锔 [Reduce] [[ONNX] fix reduce crash on scalar inputs by ganler 路 Pull Request #10780 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10780)

20. 锔 [ReduceSumSquare] [[ONNX] fix reduce crash on scalar inputs by ganler 路 Pull Request #10780 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10780)

21. 锔 [ReduceL1] [[ONNX] fix reduce crash on scalar inputs by ganler 路 Pull Request #10780 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10780)

22. 锔 [ReduceL2] [[ONNX] fix reduce crash on scalar inputs by ganler 路 Pull Request #10780 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10780)

23. 锔 [ReduceLogSum][[ONNX] fix reduce crash on scalar inputs by ganler 路 Pull Request #10780 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10780)

24. 锔 [[FIX] resolve int64/32 for AttrStmtNode by ganler 路 Pull Request #10983 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10983)

25. 锔 [Fix onnx round import with float64 inputs. by lazycal 路 Pull Request #11685 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/11685)

26. 锔 [Fix 1d-softmax schedule. by lazycal 路 Pull Request #11719 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/11719)

27. 锔 [[Fix] int32/64 mismatch of buffer elem_offset at HandleBufferBindScope by ganler 路 Pull Request #11755 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/11755)

28. 锔 [[Bug] Int64 BroadCast-ArgMax triggers assertion error at graph runtime 路 Issue #11794 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/11794)

29. 锔 [[TE Schedule] Fix broken 2D softmax TE schedules when axis=0 by lazycal 路 Pull Request #11803 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/11803)

30. 锔 [[Bug] `concat([x], axis=1)` return random results 路 Issue #11895 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/11895)

31. 锔 [Fix infercorrect layout in Layoutrewrite and improve naming. by lazycal 路 Pull Request #12007 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/12007/files)

32. 锔 [Several type mismatch fixes and checks by kparzysz-quic 路 Pull Request #12041 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/12041)

33. 锔 [[FIX][ONNX][Relay] onnx converter on matmul with scalar; bring back nn.matmul check by ganler 路 Pull Request #13448 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/13448)

34. 锔 [[Bug] Layout Error when Putting `argmin` after `conv2d` 路 Issue #9813 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/9813)

35. 锔 [Fix LayoutRewriter by lazycal 路 Pull Request #10118 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/pull/10118)

36. [[Bug] concatenating strided slice and negative padding causes wrong buffer binding 路 Issue #11897 路 apache/tvm](https://github.com/apache/tvm/issues/11897)

37. [[Bug] GPU `lower_thread_allreduce` is_zero(index) check false 路 Issue #11898 路 apache/tvm](https://github.com/apache/tvm/issues/11898)

38. [Resize does not reject unsupported layout during AlterOpLayout 路 Issue #12008 路 apache/tvm](https://github.com/apache/tvm/issues/12008)

39. [[Bug] Compilation failure for `broadcast-argmax` in internal type inference 路 Issue #13031 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/13031)

40. [[Bug] Compiled `squeeze-broadcast_to-argmin` fails at graph runtime 路 Issue #13045 路 apache/tvm 路 GitHub](https://github.com/apache/tvm/issues/13045)

### TensorRT

01. 锔 [Segfault on const+prelu+reduce_mean+comparison_op 路 Issue #1738 路 NVIDIA/TensorRT 路 GitHub](https://github.com/NVIDIA/TensorRT/issues/1738#issuecomment-1019633288)

02. 锔 [Gemm conversion error, seem to be caused by squeeze 路 Issue #824 路 onnx/onnx-tensorrt 路 GitHub](https://github.com/onnx/onnx-tensorrt/issues/824)

03. 锔 [[Bug] --loadInputs not working: input name mismatch when Flatten is the input node 路 Issue #1990 路 NVIDIA/TensorRT 路 GitHub](https://github.com/NVIDIA/TensorRT/issues/1990)

04. 锔 [Cuda OutOfMemory when creating tensor with 2^29 (~0.5 G) elements - TensorRT - NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/cuda-outofmemory-when-creating-tensor-with-2-29-0-5-g-elements/203009)

05. 锔 [Myelin error on onnx model: Assertion `i < crds_.size() < failed 路 Issue #1781 路 NVIDIA/TensorRT 路 GitHub](https://github.com/NVIDIA/TensorRT/issues/1781)

06. [Segmentation fault when using TensorRT to compile a model - TensorRT - NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/segmentation-fault-when-using-tensorrt-to-compile-a-model/218872)

07. [Internal Error: GPU error during getBestTactic: PWN(LeakyRelu_4) : misaligned address - TensorRT - NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/internal-error-gpu-error-during-getbesttactic-pwn-leakyrelu-4-misaligned-address/218832)

08. [Duplicated reshapes triggers "[graphOptimizer.cpp::findOne::510] Error Code 2: Internal Error (Assertion it != v.end() failed. )" - TensorRT - NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/duplicated-reshapes-triggers-graphoptimizer-cpp-510-error-code-2-internal-error-assertion-it-v-end-failed/203540)

09. [Incorrect slicing of boolean constant tensor with step size > 1 - TensorRT - NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/incorrect-slicing-of-boolean-constant-tensor-with-step-size-1/215793)

### TensorFlow

01. [Inconsistent behavior of Conv2D between eager mode and tracing 路 Issue #57664 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57664)

02. [TFLite fails to run a model with a dense layer following an Add operator 路 Issue #57697 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57697)

03. [TFLite throws an error with certain tensor value 路 Issue #57708 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57708)

04. [TFLite's max operator has wrong broadcasting behavior 路 Issue #57759 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57759)

05. [[TFLite] Slice-Conv2d Crash 路 Issue #58035 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/58035)

06. [pow operation gives valid output even the input is invalid 路 Issue #57757 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57757)

07. [TFLite produce wrong results when add follows a leakyrelu 路 Issue #57818 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57818)

08. [TFLite runner crashes with XOR and squeeze in the model 路 Issue #57882 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57882)

09. [Conv2D with XLA jit_compile=True fails to run 路 Issue #57748 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57748)

10. [log operator outputs wrong results with XLA compilation 路 Issue #57744 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57744)

11. [Inconsistent behavior of TF eager and XLA in int64 casting 路 Issue #57883 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57883)

12. [LRN operator outputs wrong results with `jit_compile=True` 路 Issue #57746 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57746)

13. [Conv2D layer fails to run with XLA on CUDA 路 Issue #57838 路 tensorflow/tensorflow 路 GitHub](https://github.com/tensorflow/tensorflow/issues/57838)

### Methodology

* Though most bugs are identified via individual reports, there are cases where multiple **similar-looking** bugs are merged into one report to avoid potential duplication. Nonetheless, they might be counted for multiple times according to the actual required different fixes.
* "won't fix" bugs are omitted.
* Part of the bugs are found by experimental repositories of NNSmith (e.g., PT2 bugs) but the features will be eventually upstreamed.
